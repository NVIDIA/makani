{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with Makani \n",
    "\n",
    "There are currently two ways to inference models trained in Makani: `model_package` and `inferencer`. Let us start by adding Makani to our path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makani.models.model_package import LocalPackage, load_model_package\n",
    "\n",
    "path_to_package = os.path.expanduser(\"~/Projects/fourcastnet/climate_fno/CWO-data/73VarQ/runs/sfno_linear_73chq_sc3_layers8_edim384_asgl2_cadam/ngpu64_sp1\")\n",
    "\n",
    "load_model_package(LocalPackage(path_to_package))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Inferencer\n",
    "\n",
    "The inferencer module is designed for running models directly within Makani. It supports massively parallel autoregressive roll-outs, ensemble forecasting and scoring. However, it's setup is slightly more involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To instantiate `inferencer`, we require the `params` datastructure. Thankfully, we can either use the model package for this or alternatively, use the configuration with which the model was trained.\n",
    "\n",
    "When using inferencer, a dataloader for inference is created. As such, we recommend the latter method and manually setting the path to the out-of-sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makani.utils.YParams import YParams\n",
    "\n",
    "yaml_config = os.path.join(makani_home, \"config/sfnonet_devel.yaml\")\n",
    "config =  \"sfno_linear_73chq_sc3_layers8_edim384_asgl2_cadam\"\n",
    "run_num = \"ngpu64_sp1\"\n",
    "\n",
    "params = YParams(yaml_config, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us set some extra parameters necessary for experimentation. Paths need to be adjusted but these can all be set to use the paths from the `model_package`. A lot of this is boilerplate and a rework is in progress to avoid all of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "from makani.utils.parse_dataset_metada import parse_dataset_metadata\n",
    "\n",
    "# point it to the training data\n",
    "data_dir = '/home/bbonev/Projects/fourcastnet/climate_fno/CWO-data/73VarQ/'\n",
    "\n",
    "# setting the necessary paths\n",
    "params['inf_data_path'] = os.path.join(data_dir, 'out_of_sample/') # dataset to use for inference\n",
    "params['experiment_dir'] = os.path.join(data_dir, 'runs/', config, run_num) # directory for writing out results\n",
    "params['checkpoint_path'] = os.path.join(params.experiment_dir, 'training_checkpoints/ckpt_mp0.tar') # last checkpoint\n",
    "params['best_checkpoint_path'] = os.path.join(params.experiment_dir, 'training_checkpoints/best_ckpt_mp0.tar') # best checkpoint\n",
    "params['metadata_json_path'] = os.path.join(data_dir, 'invariants/data.json') # data.json file - see README for detailed info\n",
    "\n",
    "# where to find normalization \n",
    "params['min_path'] = os.path.join(data_dir, 'stats/mins.npy')\n",
    "params['max_path'] = os.path.join(data_dir, 'stats/maxs.npy')\n",
    "params['time_means_path'] = os.path.join(data_dir, 'stats/time_means.npy')\n",
    "params['global_means_path'] = os.path.join(data_dir, 'stats/global_means.npy')\n",
    "params['global_stds_path'] =  os.path.join(data_dir, 'stats/global_stds.npy')\n",
    "params['time_diff_means_path'] = os.path.join(data_dir, 'stats/time_diff_means.npy')\n",
    "params['time_diff_stds_path'] = os.path.join(data_dir, 'stats/time_diff_stds.npy')\n",
    "\n",
    "# land-sea-mask and orography\n",
    "params['orography_path'] = os.path.join(data_dir, 'invariants/orography.nc')\n",
    "params['landmask_path'] = os.path.join(data_dir, 'invariants/land_mask.nc')\n",
    "\n",
    "# set parameters which can be read from the metadata file\n",
    "params, _ = parse_dataset_metadata(params['metadata_json_path'], params=params)\n",
    "\n",
    "params['multifiles'] = True # use the multifiles dataloader (not DALI)\n",
    "params['n_future'] = 0 # predict one step at a time\n",
    "params['valid_autoreg_steps'] = 20\n",
    "params['split_data_channels'] = False \n",
    "\n",
    "# do not log to wandb\n",
    "params['log_to_wandb'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makani import Inferencer\n",
    "\n",
    "inferencer = Inferencer(params, world_rank=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select some channels we want to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_channels = [\"u10m\", \"v10m\", \"z500\", \"t2m\"]\n",
    "output_channels = [params[\"channel_names\"].index(ch) for ch in output_channels]\n",
    "output_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the API provided in inferencer takes in an initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth, pred, _, acc_curve, rmse_curve = inferencer.inference_single(ic=0, output_data=True, output_channels=output_channels, compute_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = torch.arange((params.valid_autoreg_steps+1))*params.dhours\n",
    "plt.plot(t, acc_curve[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makani.utils.visualize import plot_comparison\n",
    "\n",
    "plot_comparison(pred[-1, 0, 0], truth[-1, 0, 0], diverging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
