{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b791202-60fa-4aec-8231-2bfe82698013",
   "metadata": {},
   "source": [
    "# Inference through makani model package\n",
    "\n",
    "## General\n",
    "\n",
    "While we generally suggest using Makani's `inferencer.py` module or Earth2Studio for inference, it can be useful to use stand-along model packages. To support this, makani intrduces a model package format, which we showcase here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238aea2b-c1c0-42bf-bc64-a57b79946189",
   "metadata": {},
   "source": [
    "## Setting up the model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e56f1-780f-4d9a-aea5-e7d4005a44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"expandable_segments:True\"\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from makani.models.model_package import LocalPackage, load_model_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b82ed-fec9-452e-8b89-8fb5d9107b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device that we want to use\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# directory where the model package resides\n",
    "model_package_dir = \"/runs/fcn3_sc2_edim45_layers10_finetune_2013-2016_8step_centered_4member/flexible\"\n",
    "\n",
    "model_package = load_model_package(LocalPackage(model_package_dir)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78819b-e838-429c-be8d-cdaf8b74f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = model_package.params.channel_names\n",
    "timestep = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a125d4-a171-4ff9-bd94-6919fe2df6fe",
   "metadata": {},
   "source": [
    "## load data from local HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9729e-4f25-4efa-8b1b-acce22daa54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import json\n",
    "\n",
    "era5_2018_file = h5.File(\"/out_of_sample/2018.h5\", \"r\")\n",
    "era5_2018_data = era5_2018_file[\"fields\"]\n",
    "\n",
    "# get the channel names from the desciption file\n",
    "era5_2018_desc_file = open(\"/metadata/data.json\")\n",
    "era5_metadata = json.load(era5_2018_desc_file)\n",
    "era5_2018_desc_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98293011-ff1c-40cc-b609-968a2e112269",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_channels = era5_metadata[\"coords\"][\"channel\"]\n",
    "era5_dhours = era5_metadata[\"dhours\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c2473-010f-43db-838d-fd2aa17d2c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "iic = 0\n",
    "ic_time = datetime.fromisoformat(\"2018-01-01T00:00:00+00:00\") + timedelta(hours=iic * era5_dhours)\n",
    "\n",
    "ich = [era5_channels.index(c) for c in variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704076c1-bbe9-4c4d-ab4b-a46447309997",
   "metadata": {},
   "source": [
    "## do the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4385072-5d9d-4fd4-8358-aecb544147e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreg_steps = 18\n",
    "\n",
    "inpt = torch.as_tensor(era5_2018_data[iic, ich]).to(device)\n",
    "time = ic_time\n",
    "\n",
    "# normalize the input now to avoid jumping back and forthabs\n",
    "inpt = (inpt - model_package.in_bias)/model_package.in_scale\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.inference_mode():\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            \n",
    "            pred = inpt.clone()\n",
    "\n",
    "            for idt in range(autoreg_steps):\n",
    "                pred = model_package(pred, time, normalized_data=True, replace_state=True)\n",
    "                time += timedelta(hours=timestep)\n",
    "\n",
    "pred = pred * model_package.out_scale + model_package.out_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e283a6-475c-4a91-9891-a5df8760e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch_harmonics.plotting import plot_sphere\n",
    "\n",
    "plt_channel = \"u10m\"\n",
    "\n",
    "ground_truth = era5_2018_data[iic+autoreg_steps, era5_channels.index(plt_channel)]\n",
    "prediction = pred.cpu().detach().numpy()[0, variables.index(plt_channel)]\n",
    "\n",
    "vmax = np.abs(ground_truth).max()\n",
    "vmin = -vmax\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plot_sphere(prediction, title = f\"FCN3 prediction at {time}\", vmin=vmin, vmax=vmax, fig=fig)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plot_sphere(ground_truth, title = f\"ERA5 ground truth at {time}\", vmin=vmin, vmax=vmax, fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930c14c-9f78-4f55-8e36-bf848d150f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
